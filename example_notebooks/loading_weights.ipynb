{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading file\n",
    "[Source](http://files.fast.ai/models/wt103/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from training_utils import training_loop, test_loop\n",
    "from model import RNNLM\n",
    "# from data_utils import IndexVectorizer, TextDataset, simple_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_pre_trained_models = '../../data/weights_pretrained/'\n",
    "new_data_directory = '../../data/imdb/models/'\n",
    "os.makedirs(directory_pre_trained_models, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.fast.ai/models/wt103/fwd_wt103_enc.h5 -O $directory_pre_trained_models/fwd_wt103_enc.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can skip this one V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.fast.ai/models/wt103/fwd_wt103.h5 -O $directory_pre_trained_models/fwd_wt103.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.fast.ai/models/wt103/itos_wt103.pkl -O $directory_pre_trained_models/fitos_wt103.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 886M\r\n",
      "drwxrwxr-x. 5 frido frido   56 Feb 12 21:38 ..\r\n",
      "-rwxr-xr-x. 1 root  root  441M Feb 12 17:18 fwd_wt103.h5\r\n",
      "drwxrwsr-x. 2 root  root    73 Feb 12 17:18 .\r\n",
      "-rwxr-xr-x. 1 root  root  441M Feb 12 17:18 fwd_wt103_enc.h5\r\n",
      "-rwxr-xr-x. 1 root  root  4.0M Feb 12 17:18 fitos_wt103.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ltha $directory_pre_trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_file = os.path.join(directory_pre_trained_models, 'fwd_wt103.h5')\n",
    "weights_file = os.path.join(directory_pre_trained_models, 'fwd_wt103_enc.h5')\n",
    "fitos_file = os.path.join(directory_pre_trained_models, 'fitos_wt103.pkl')\n",
    "vectorizer_file = os.path.join(new_data_directory, 'lm_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(weights_file, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = torch.load(encoder_file, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU variables\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device_num = 0\n",
    "device = torch.device(f\"cuda:{device_num}\" if False else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 238462\n",
    "embedding_size = 400\n",
    "hidden_size = 1150\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'encoder', 'weight']\n",
      "name 'lm' is not defined\n",
      "name 'layer' is not defined\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5da7fca89dcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# this is what assigns the new value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layer' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5da7fca89dcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_detail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# # load weights\n",
    "# for k, v in enc.items():    \n",
    "#     layer_detail = k.split('.')\n",
    "#     layer_name = layer_detail[-1].replace('_raw', '')\n",
    "    \n",
    "#     print(layer_detail)\n",
    "\n",
    "#     try:\n",
    "#         layer = getattr(lm, layer_detail[1])\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "        \n",
    "#     # which rnn, and what layer???\n",
    "#     if layer_detail[1] == 'rnns':\n",
    "#         n_rnn = int(layer_detail[2])\n",
    "#         layer = layer[n_rnn]\n",
    "#     try:\n",
    "#         # this is what assigns the new value\n",
    "#         getattr(layer, layer_name).data = v\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(e)(layer_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_enc = {}\n",
    "for k,v in enc.items():\n",
    "    layer_detail = k.split('.')\n",
    "    layer_name = layer_detail[-1].replace('_raw', '')\n",
    "    if len(layer_detail) == num_layers: \n",
    "        new_enc[f'{layer_detail[1]}.{layer_name}'] = v\n",
    "    else:\n",
    "        new_enc[f'{layer_detail[1]}.{layer_detail[2]}.{layer_name}'] = v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove this odd element as it is the same as encoder.weight\n",
    "#new_enc['encoder_with_dropout.embed.weight'] == new_enc['encoder.weight']\n",
    "del new_enc['encoder_with_dropout.embed.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our vectorizer\n",
    "\n",
    "## Load the wikitext vocabulary\n",
    "pretrained_idx2word = pickle.load(open(fitos_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_word2idx = {k: i for i,k in enumerate(pretrained_idx2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_vectorizer = pickle.load(open(vectorizer_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_encoder_weights = enc['0.encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_m = pretrained_encoder_weights.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_m = [x.item() for x in row_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab_size = len(new_model_vectorizer.word2idx)\n",
    "new_encoder_weights = torch.tensor([row_m for i in range(new_vocab_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_idx2weights = {}\n",
    "for word, i in new_model_vectorizer.word2idx.items():\n",
    "    if word in pretrained_word2idx:\n",
    "        word_idx = pretrained_word2idx[word]\n",
    "        new_encoder_weights[i] = pretrained_encoder_weights[word_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "new_enc['encoder.weight'] = new_encoder_weights\n",
    "new_enc['decoder.weight'] = copy.copy(new_encoder_weights)\n",
    "new_enc['decoder.bias'] = torch.zeros(new_enc['decoder.weight'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.weight torch.Size([20004, 400])\n",
      "rnns.0.weight_ih_l0 torch.Size([4600, 400])\n",
      "rnns.0.weight_hh_l0 torch.Size([4600, 1150])\n",
      "rnns.0.bias_ih_l0 torch.Size([4600])\n",
      "rnns.0.bias_hh_l0 torch.Size([4600])\n",
      "rnns.1.weight_ih_l0 torch.Size([4600, 1150])\n",
      "rnns.1.weight_hh_l0 torch.Size([4600, 1150])\n",
      "rnns.1.bias_ih_l0 torch.Size([4600])\n",
      "rnns.1.bias_hh_l0 torch.Size([4600])\n",
      "rnns.2.weight_ih_l0 torch.Size([1600, 1150])\n",
      "rnns.2.weight_hh_l0 torch.Size([1600, 400])\n",
      "rnns.2.bias_ih_l0 torch.Size([1600])\n",
      "rnns.2.bias_hh_l0 torch.Size([1600])\n",
      "decoder.weight torch.Size([20004, 400])\n",
      "decoder.bias torch.Size([20004])\n"
     ]
    }
   ],
   "source": [
    "for k,v in lm.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a model\n",
    "lm = RNNLM(device=device, vocab_size=new_vocab_size, \n",
    "           embedding_size=embedding_size, hidden_size=hidden_size, \n",
    "           batch_size=64, num_layers=3, tie_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(lm.encoder.weight) == id(lm.decoder.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.load_state_dict(new_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(lm.encoder.weight) == id(lm.decoder.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RNNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139644474457288"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "id(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139644474457288"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 9]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139644473930248"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
