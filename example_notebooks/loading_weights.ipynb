{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading file\n",
    "[Source](http://files.fast.ai/models/wt103/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from training_utils import training_loop, test_loop\n",
    "from model_v2 import RNNLM\n",
    "# from data_utils import IndexVectorizer, TextDataset, simple_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_pre_trained_models = '/scratch/olympus/projects/sentiment_analysis/machine_learnining/weights_pretrained'\n",
    "os.makedirs(directory_pre_trained_models, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.fast.ai/models/wt103/fwd_wt103_enc.h5 -O $directory_pre_trained_models/fwd_wt103_enc.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can skip this one V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.fast.ai/models/wt103/fwd_wt103.h5 -O $directory_pre_trained_models/fwd_wt103.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.fast.ai/models/wt103/itos_wt103.pkl -O $directory_pre_trained_models/fitos_wt103.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 886M\n",
      "drwxrws---+ 2 ly501 smapp 4.0K Dec  4 17:15 .\n",
      "drwxrws---+ 3 ly501 smapp 4.0K Dec  4 17:11 ..\n",
      "-rwxrwx---+ 1 ly501 smapp 441M Mar 28  2018 fwd_wt103.h5\n",
      "-rwxrwx---+ 1 ly501 smapp 441M Mar 28  2018 fwd_wt103_enc.h5\n",
      "-rwxrwx---+ 1 ly501 smapp 4.0M Mar 28  2018 fitos_wt103.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls -ltha $directory_pre_trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_file = os.path.join(directory_pre_trained_models, 'fwd_wt103.h5')\n",
    "weights_file = os.path.join(directory_pre_trained_models, 'fwd_wt103_enc.h5')\n",
    "fitos_file = os.path.join(directory_pre_trained_models, 'fitos_wt103.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(weights_file, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = torch.load(encoder_file, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.encoder.weight:    torch.Size([238462, 400])\n",
      "0.encoder_with_dropout.embed.weight:    torch.Size([238462, 400])\n",
      "0.rnns.0.module.weight_ih_l0:    torch.Size([4600, 400])\n",
      "0.rnns.0.module.bias_ih_l0:    torch.Size([4600])\n",
      "0.rnns.0.module.bias_hh_l0:    torch.Size([4600])\n",
      "0.rnns.0.module.weight_hh_l0_raw:    torch.Size([4600, 1150])\n",
      "0.rnns.1.module.weight_ih_l0:    torch.Size([4600, 1150])\n",
      "0.rnns.1.module.bias_ih_l0:    torch.Size([4600])\n",
      "0.rnns.1.module.bias_hh_l0:    torch.Size([4600])\n",
      "0.rnns.1.module.weight_hh_l0_raw:    torch.Size([4600, 1150])\n",
      "0.rnns.2.module.weight_ih_l0:    torch.Size([1600, 1150])\n",
      "0.rnns.2.module.bias_ih_l0:    torch.Size([1600])\n",
      "0.rnns.2.module.bias_hh_l0:    torch.Size([1600])\n",
      "0.rnns.2.module.weight_hh_l0_raw:    torch.Size([1600, 400])\n",
      "1.decoder.weight:    torch.Size([238462, 400])\n"
     ]
    }
   ],
   "source": [
    "for k,v in enc.items():\n",
    "    print(f'{k}:    {v.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# they're the same vals\n",
    "wgts['rnns.2.module.bias_hh_l0'] == enc['0.rnns.2.module.bias_hh_l0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU variables\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device_num = 0\n",
    "device = torch.device(f\"cuda:{device_num}\" if use_gpu else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 238462\n",
    "embedding_size = 400\n",
    "hidden_size = 4600\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a model\n",
    "lm = RNNLM(device, vocab_size, embedding_size, hidden_size, 256, num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', 'encoder', 'weight']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'encoder', 'weight']\n",
      "['0', 'encoder_with_dropout', 'embed', 'weight']\n",
      "'RNNLM' object has no attribute 'encoder_with_dropout'\n",
      "['0', 'rnns', '0', 'module', 'weight_ih_l0']\n",
      "['0', 'rnns', '0', 'module', 'bias_ih_l0']\n",
      "['0', 'rnns', '0', 'module', 'bias_hh_l0']\n",
      "['0', 'rnns', '0', 'module', 'weight_hh_l0_raw']\n",
      "['0', 'rnns', '1', 'module', 'weight_ih_l0']\n",
      "['0', 'rnns', '1', 'module', 'bias_ih_l0']\n",
      "['0', 'rnns', '1', 'module', 'bias_hh_l0']\n",
      "['0', 'rnns', '1', 'module', 'weight_hh_l0_raw']\n",
      "['0', 'rnns', '2', 'module', 'weight_ih_l0']\n",
      "['0', 'rnns', '2', 'module', 'bias_ih_l0']\n",
      "['0', 'rnns', '2', 'module', 'bias_hh_l0']\n",
      "['0', 'rnns', '2', 'module', 'weight_hh_l0_raw']\n",
      "['1', 'decoder', 'weight']\n"
     ]
    }
   ],
   "source": [
    "# load weights\n",
    "for k, v in enc.items():    \n",
    "    layer_detail = k.split('.')\n",
    "    layer_name = layer_detail[-1].replace('_raw', '')\n",
    "    \n",
    "    print(layer_detail)\n",
    "\n",
    "    try:\n",
    "        layer = getattr(lm, layer_detail[1])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    # which rnn, and what layer???\n",
    "    if layer_detail[1] == 'rnns':\n",
    "        n_rnn = int(layer_detail[2])\n",
    "        layer = layer[n_rnn]\n",
    "    try:\n",
    "        # this is what assigns the new value\n",
    "        getattr(layer, layer_name).data = v\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)(layer_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
