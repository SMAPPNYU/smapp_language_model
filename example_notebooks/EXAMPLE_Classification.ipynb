{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifierModel import EncoderModel, ClassifierModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "\n",
    "from data_utils import (IndexVectorizer,\n",
    "                        SpacyTokenizer,\n",
    "                        TextDataset,\n",
    "                        LMDataLoader,\n",
    "                        CLFDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "# GPU setup\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device_num = 0\n",
    "device = torch.device(f\"cuda:{device_num}\" if use_gpu else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/imdb/'\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, 'train.csv')\n",
    "VALID_PATH = os.path.join(DATA_DIR, 'valid.csv')\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "valid = pd.read_csv(VALID_PATH)\n",
    "\n",
    "vectorizer = pickle.load(open(\"lm_vectorizer.pkl\", \"rb\"))\n",
    "train_ds = TextDataset(data=train, vectorizer=vectorizer, \n",
    "                       text_col='text', label_col='label')\n",
    "valid_ds = TextDataset(data=valid, vectorizer=vectorizer, \n",
    "                       text_col='text', label_col='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = CLFDataLoader(dataset=train_ds, batch_size=BATCH_SIZE)\n",
    "valid_dl = CLFDataLoader(dataset=valid_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the language model weights  \n",
    "# but remove the decoder \n",
    "d = torch.load(DATA_DIR+\"models/LM__2019-02-01.json\")\n",
    "del d[\"decoder.weight\"]\n",
    "del d[\"decoder.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the (document)Encoder model \n",
    "# from the language model weights\n",
    "embedding_size = d['encoder.weight'].shape[1]\n",
    "hidden_size = d['lstm1.weight_hh_l0'].shape[1]\n",
    "m = EncoderModel(vectorizer, hidden_size, embedding_size, bidirectional=False)\n",
    "m.load_state_dict(d)\n",
    "m.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it together with the classification head\n",
    "c = ClassifierModel(lm_hidden_size=hidden_size, hidden_size=200, output_size=3)\n",
    "final = nn.Sequential(m,c)\n",
    "if use_gpu:\n",
    "    final = final.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred_probs, true_class):\n",
    "    '''Calculates average accuracy over batch'''\n",
    "    pred_class = torch.argmax(pred_probs, dim=1)\n",
    "    errors = pred_class == y\n",
    "    return torch.mean(errors.type(torch.float)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "\tTraining accuracy: 0.621\n",
      "\tValidation accuracy: 0.701\n",
      "Epoch 1:\n",
      "\tTraining accuracy: 0.65\n",
      "\tValidation accuracy: 0.71\n",
      "Epoch 2:\n",
      "\tTraining accuracy: 0.503\n",
      "\tValidation accuracy: 0.5\n",
      "Epoch 3:\n",
      "\tTraining accuracy: 0.511\n",
      "\tValidation accuracy: 0.7\n",
      "Epoch 4:\n",
      "\tTraining accuracy: 0.524\n",
      "\tValidation accuracy: 0.5\n",
      "Epoch 5:\n",
      "\tTraining accuracy: 0.5\n",
      "\tValidation accuracy: 0.5\n",
      "Epoch 6:\n",
      "\tTraining accuracy: 0.5\n",
      "\tValidation accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(final.parameters(), lr = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    final.train()\n",
    "    epoch_train_accs = []\n",
    "    for x, y in train_dl:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        final.zero_grad()\n",
    "        res = final(x)\n",
    "        error = criterion(res, y)\n",
    "        error.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_accs.append(get_accuracy(res, y))\n",
    "        del error\n",
    "        \n",
    "    # Validation accuracy\n",
    "    with torch.no_grad():\n",
    "        final.eval()\n",
    "        epoch_train_acc = round(np.mean(epoch_train_accs), 3)\n",
    "        valid_accs = []\n",
    "        for x, y in valid_dl:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred_prob = final(x)\n",
    "            valid_accs.append(get_accuracy(pred_prob, y))\n",
    "        valid_acc = round(np.mean(valid_accs), 3)\n",
    "        print(f'Epoch {epoch}:\\n\\tTraining accuracy: {epoch_train_acc}\\n\\tValidation accuracy: {valid_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
